{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mathematical Operations in PyTorch(vs. NumPy).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCA/IH7fIrgtwWXsk2wk6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lax17/PyTorch/blob/master/Mathematical_Operations_in_PyTorch(vs_NumPy).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8k9msIxJO54",
        "colab_type": "text"
      },
      "source": [
        "Installing PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq4aCiGCKcZW",
        "colab_type": "code",
        "outputId": "1a03f4e6-bba3-4731-c5f4-fc91e61334ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "!pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.2.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.2.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl (663.1MB)\n",
            "\u001b[K     |████████████████████████████████| 663.1MB 26kB/s \n",
            "\u001b[?25hCollecting torchvision==0.4.0+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.4.0%2Bcu92-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.2.0+cu92) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0+cu92) (1.12.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torch-1.2.0+cu92 torchvision-0.4.0+cu92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTKoMZsWgMmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcSh1oUmg1Jf",
        "colab_type": "text"
      },
      "source": [
        "**Mathematical Operations in PyTorch(vs. NumPy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHHhWiJVg63K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "263e3251-bc8d-47c7-ba74-30853bd0b865"
      },
      "source": [
        "'''We will initialize two arrays and then perform mathematical operations like addition, subtraction, multiplication, and division, on them:'''\n",
        "# initializing two arrays\n",
        "a = np.array(2)\n",
        "b = np.array(1)\n",
        "print(a,b)   \n",
        "# addition\n",
        "print(a+b)\n",
        "\n",
        "# subtraction\n",
        "print(b-a)\n",
        "\n",
        "# multiplication\n",
        "print(a*b)\n",
        "\n",
        "# division\n",
        "print(a/b)\n",
        "\n",
        "# initializing two tensors\n",
        "a = torch.tensor(2)\n",
        "b = torch.tensor(1)\n",
        "print(a,b)\n",
        "# addition\n",
        "print(a+b)\n",
        "\n",
        "# subtraction\n",
        "print(b-a)\n",
        "\n",
        "# multiplication\n",
        "print(a*b)\n",
        "\n",
        "# division\n",
        "print(a/b)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 1\n",
            "3\n",
            "-1\n",
            "2\n",
            "2.0\n",
            "tensor(2) tensor(1)\n",
            "tensor(3)\n",
            "tensor(-1)\n",
            "tensor(2)\n",
            "tensor(2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh4BY2_AWMut",
        "colab_type": "text"
      },
      "source": [
        "**Matrix Operations in PyTorch(vs. NumPy)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjQWVt80WYkK",
        "colab_type": "text"
      },
      "source": [
        "*Matrix* *Initialization*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joRqkEQLWMVP",
        "colab_type": "code",
        "outputId": "6a5b81a6-9a44-43a7-e270-c707b416c009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "'''Let’s say we want a matrix of shape 3*3 having all zeros. Take a moment to think – how can we do that using NumPy?'''\n",
        "\n",
        "a = np.zeros((3,3))\n",
        "print(a)\n",
        "print(a.shape) \n",
        "\n",
        "'''Fairly straightforward. We just have to use the zeros() function of NumPy and pass the desired shape ((3,3) in our case), and we get a matrix consisting of all zeros. Let’s now see how we can do this in PyTorch:'''\n",
        "\n",
        "a = torch.zeros((3,3))\n",
        "print(a)\n",
        "print(a.shape) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "(3, 3)\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVLRfyBmYMDu",
        "colab_type": "code",
        "outputId": "904530d9-13db-4680-ee4e-8c4b9f5fd65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "'''Now, while building a neural network, we randomly initialize the weights for the model. \n",
        "So, let’s see how we can initialize a matrix with random numbers:'''\n",
        "# setting the random seed for numpy\n",
        "np.random.seed(42)\n",
        "#matrix of random numbers\n",
        "a = np.random.randn(3,3)\n",
        "print(a)\n",
        "# setting the random seed for pytorch\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(3,3)\n",
        "print(a)\n",
        "\n",
        "'''This is where even more similarities with NumPy crop up.\n",
        " PyTorch also has a function called randn() that returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution).'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.49671415 -0.1382643   0.64768854]\n",
            " [ 1.52302986 -0.23415337 -0.23413696]\n",
            " [ 1.57921282  0.76743473 -0.46947439]]\n",
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380,  0.4617]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUo8U6R6d8A7",
        "colab_type": "text"
      },
      "source": [
        "*Matrix* *Operation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5xC9kA9eGPP",
        "colab_type": "code",
        "outputId": "57b1d9b9-8914-4f66-f51f-b372ac6ab433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "# setting the random seed for numpy and initializing two matrices\n",
        "np.random.seed(42)\n",
        "a = np.random.randn(3,3)\n",
        "b = np.random.randn(3,3)\n",
        "\n",
        "# matrix addition\n",
        "print(np.add(a,b), '\\n')\n",
        "\n",
        "# matrix subtraction\n",
        "print(np.subtract(a,b), '\\n')\n",
        " \n",
        "# matrix multiplication\n",
        "print(np.dot(a,b), '\\n')\n",
        " \n",
        "# matrix multiplication\n",
        "print(np.divide(a,b))\n",
        "\n",
        "# setting the random seed for pytorch and initializing two tensors\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(3,3)\n",
        "b = torch.randn(3,3)\n",
        "# matrix addition\n",
        "print(torch.add(a,b), '\\n')\n",
        "\n",
        "# matrix subtraction\n",
        "print(torch.sub(a,b), '\\n')\n",
        "\n",
        "# matrix multiplication\n",
        "print(torch.mm(a,b), '\\n')\n",
        "\n",
        "# matrix division\n",
        "print(torch.div(a,b))\n",
        "'''Note that the .mm() function of PyTorch is similar to the dot product in NumPy. \n",
        "This function will be helpful when we create our model from scratch in PyTorch. '''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.0392742  -0.60168199  0.18195878]\n",
            " [ 1.76499213 -2.14743362 -1.95905479]\n",
            " [ 1.01692529 -0.24539639 -0.15522705]] \n",
            "\n",
            "[[-0.04584589  0.32515339  1.11341829]\n",
            " [ 1.28106758  1.67912687  1.49078088]\n",
            " [ 2.14150034  1.78026585 -0.78372172]] \n",
            "\n",
            "[[-0.12814468 -0.62164688  0.21069439]\n",
            " [ 0.90133115 -0.02065676 -0.3790019 ]\n",
            " [ 1.30648762 -1.7246546  -2.20677932]] \n",
            "\n",
            "[[ 0.9155008   0.29835784 -1.39069607]\n",
            " [ 6.29449313  0.12238321  0.13573803]\n",
            " [-2.80855031 -0.75771243 -1.49396459]]\n",
            "tensor([[ 0.6040,  0.6637,  1.0438],\n",
            "        [ 1.3406, -2.8127, -1.1753],\n",
            "        [ 3.1662,  0.6841,  1.2788]]) \n",
            "\n",
            "tensor([[ 0.0693, -0.4061, -0.5749],\n",
            "        [-0.8800,  0.5669,  0.8026],\n",
            "        [ 1.2502, -1.9601, -0.3555]]) \n",
            "\n",
            "tensor([[ 0.4576,  0.2724,  0.3367],\n",
            "        [-1.3636,  1.7743,  1.1446],\n",
            "        [ 0.3243,  2.8696,  2.7954]]) \n",
            "\n",
            "tensor([[ 1.2594,  0.2408,  0.2897],\n",
            "        [ 0.2075,  0.6645,  0.1884],\n",
            "        [ 2.3051, -0.4826,  0.5649]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBfzm4RogDgT",
        "colab_type": "code",
        "outputId": "029f8cdf-0bbf-44e2-a7e0-da1a89db2185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "'''Matrix transpose is one technique which is also very useful while creating a neural network from scratch.\n",
        " So let’s see how we take the transpose of a matrix in NumPy:'''\n",
        "\n",
        " # original matrix\n",
        "print(a, '\\n') \n",
        "\n",
        "# matrix transpose\n",
        "print(np.transpose(a))\n",
        "\n",
        "# original matrix\n",
        "print(a, '\\n')\n",
        "\n",
        "# matrix transpose\n",
        "print(torch.t(a))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380,  0.4617]]) \n",
            "\n",
            "tensor([[ 0.3367,  0.2303,  2.2082],\n",
            "        [ 0.1288, -1.1229, -0.6380],\n",
            "        [ 0.2345, -0.1863,  0.4617]])\n",
            "tensor([[ 0.3367,  0.1288,  0.2345],\n",
            "        [ 0.2303, -1.1229, -0.1863],\n",
            "        [ 2.2082, -0.6380,  0.4617]]) \n",
            "\n",
            "tensor([[ 0.3367,  0.2303,  2.2082],\n",
            "        [ 0.1288, -1.1229, -0.6380],\n",
            "        [ 0.2345, -0.1863,  0.4617]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn7efd-0jBrN",
        "colab_type": "text"
      },
      "source": [
        "Concatenating Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcDlgrdojAwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "242bc5b8-743d-4974-8191-bf51e7d10a3c"
      },
      "source": [
        "# initializing two tensors\n",
        "a = torch.tensor([[1,2],[3,4]])\n",
        "b = torch.tensor([[5,6],[7,8]])\n",
        "print(a, '\\n')\n",
        "print(b)\n",
        "\n",
        "'''What if we want to concatenate these tensors vertically? We can use the below code:'''\n",
        "# concatenating vertically\n",
        "print(torch.cat((a,b)))\n",
        "\n",
        "'''As you can see, the second tensor has been stacked below the first tensor.\n",
        " We can concatenate the tensors horizontally as well by setting the dim parameter to 1:'''\n",
        " \n",
        "# concatenating horizontally\n",
        "print(torch.cat((a,b),dim=1))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "tensor([[5, 6],\n",
            "        [7, 8]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "tensor([[1, 2, 5, 6],\n",
            "        [3, 4, 7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnk0M-9tjP_R",
        "colab_type": "text"
      },
      "source": [
        "*Reshaping* *Tensors*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WDi6i_SkY5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "e379d02c-6b37-4f95-fe1f-01984925d329"
      },
      "source": [
        "# setting the random seed for pytorch\n",
        "torch.manual_seed(42)\n",
        "# initializing tensor\n",
        "a = torch.randn(2,4)\n",
        "print(a)\n",
        "print(a.shape)\n",
        "\n",
        "'''We can use the .reshape() function and pass the required shape as a parameter. \n",
        "Let’s try to convert the above tensor of shape (2,4) to a tensor of shape (1,8):'''\n",
        "\n",
        "b = a.reshape(1,8)\n",
        "print(b)\n",
        "b.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303],\n",
            "        [-1.1229, -0.1863,  2.2082, -0.6380]])\n",
            "torch.Size([2, 4])\n",
            "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puHQzQEFlBfP",
        "colab_type": "text"
      },
      "source": [
        "Awesome! PyTorch also provides the functionality to convert NumPy arrays to tensors. You can use the below code to do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-7q6kGxlSIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "28d6c4a2-1a3e-412b-f925-be7532d9474a"
      },
      "source": [
        "# initializing a numpy array\n",
        "a = np.array([[1,2],[3,4]])\n",
        "print(a, '\\n')\n",
        "\n",
        "# converting the numpy array to tensor\n",
        "tensor = torch.from_numpy(a)\n",
        "print(tensor)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]] \n",
            "\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HUMp4vTlWO1",
        "colab_type": "text"
      },
      "source": [
        "**Common PyTorch Modules**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1jccdrFlnP5",
        "colab_type": "text"
      },
      "source": [
        "**Autograd** **Module**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHAZqrBl0hr",
        "colab_type": "text"
      },
      "source": [
        "The autograd module helps us to compute the gradients in the forward pass itself which saves a lot of computation time of an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S51QaPImwkYp",
        "colab_type": "code",
        "outputId": "4e02849e-b0d3-4dab-c469-df6171f2b636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# initializing a tensor\n",
        "a = torch.ones((2,2), requires_grad=True)\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJW6gVUwmlN",
        "colab_type": "code",
        "outputId": "5b55a73a-209a-4433-d62e-4839de7773c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "b = a + 5\n",
        "c = b.mean()\n",
        "print(b,c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.]], grad_fn=<AddBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtTWyUdqwq1H",
        "colab_type": "code",
        "outputId": "d7ce5b55-e5e6-405e-dc33-c14e175b3350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# back propagating\n",
        "c.backward() \n",
        "\n",
        "# computing gradients\n",
        "print(a.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwzP9clzmTBm",
        "colab_type": "text"
      },
      "source": [
        "**Optim** **Module**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMqEyrg_mc65",
        "colab_type": "text"
      },
      "source": [
        "The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt7bTSpAmWsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the optim module\n",
        "from torch import optim\n",
        "\n",
        "# adam\n",
        "## adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# sgd\n",
        "## SGD = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9dDTI00mtsJ",
        "colab_type": "text"
      },
      "source": [
        "**nn** **Module**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMdWO_M5mnuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The autograd module in PyTorch helps us define computation graphs as we proceed in the model. \n",
        "# But, just using the autograd module can be low-level when we are dealing with a complex neural network.\n",
        "\n",
        "# In those cases, we can make use of the nn module. \n",
        "# This defines a set of functions, similar to the layers of a neural network, which takes the input from the previous state and produces an output."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Building a Neural Network from Scratch in PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kHfj5gd_iWv",
        "colab_type": "text"
      },
      "source": [
        "**Building a Neural Network from Scratch in PyTorch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLUJbiHu_5QL",
        "colab_type": "text"
      },
      "source": [
        "This is going to be a lot of fun so letâ€™s get right down to it. We will first initialize the input and output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMz1BmsX_sqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c0f67ef3-f9e3-425a-e736-d13a2426d54c"
      },
      "source": [
        "import torch\n",
        "#Input tensor\n",
        "X = torch.Tensor([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
        "#Output\n",
        "y = torch.Tensor([[1],[1],[0]])\n",
        "print(X, '\\n')\n",
        "print(y)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 1., 0.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [0., 1., 0., 1.]]) \n",
            "\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGHaZZhm_-gw",
        "colab_type": "text"
      },
      "source": [
        "Next, we will define the sigmoid function which will act as the activation function and the derivative of the sigmoid function which will help us in the backpropagation step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIFqQhW7AJc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sigmoid Function\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + torch.exp(-x))\n",
        "\n",
        "#Derivative of Sigmoid Function/\n",
        "def derivatives_sigmoid(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVZgP2qdAIT4",
        "colab_type": "text"
      },
      "source": [
        "Next, initialize the parameters for our model including the number of epochs, learning rate, weights, biases, etc.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNfl8NPwAYn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Variable initialization\n",
        "epoch=7000 #Setting training iterations\n",
        "lr=0.1 #Setting learning rate\n",
        "inputlayer_neurons = X.shape[1] #number of features in data set\n",
        "hiddenlayer_neurons = 3 #number of hidden layer neurons\n",
        "output_neurons = 1 #number of neurons in output layer\n",
        "\n",
        "#weight and bias initialization\n",
        "wh=torch.randn(inputlayer_neurons, hiddenlayer_neurons).type(torch.FloatTensor)\n",
        "bh=torch.randn(1, hiddenlayer_neurons).type(torch.FloatTensor)\n",
        "wout=torch.randn(hiddenlayer_neurons, output_neurons)\n",
        "bout=torch.randn(1, output_neurons)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh2EUkpfAToC",
        "colab_type": "text"
      },
      "source": [
        "Here we have randomly initialized the weights and biases using the .randn() function .we will create a neural network.There is a single hidden layer and an input and an output layer in the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEwFdxgA6dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(epoch):\n",
        "    #Forward Propogation\n",
        "    hidden_layer_input1 = torch.mm(X, wh)\n",
        "    hidden_layer_input = hidden_layer_input1 + bh\n",
        "    hidden_layer_activations = sigmoid(hidden_layer_input)\n",
        "\n",
        "    output_layer_input1 = torch.mm(hidden_layer_activations, wout)\n",
        "    output_layer_input = output_layer_input1 + bout\n",
        "    output = sigmoid(output_layer_input)\n",
        "\n",
        "    #Backpropagation\n",
        "    E = y-output\n",
        "    slope_output_layer = derivatives_sigmoid(output)\n",
        "    slope_hidden_layer = derivatives_sigmoid(hidden_layer_activations)\n",
        "    d_output = E * slope_output_layer\n",
        "    Error_at_hidden_layer = torch.mm(d_output, wout.t())\n",
        "    d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
        "    wout += torch.mm(hidden_layer_activations.t(), d_output) *lr\n",
        "    bout += d_output.sum() *lr\n",
        "    wh += torch.mm(X.t(), d_hiddenlayer) *lr\n",
        "    bh += d_output.sum() *lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6YLQx_oBUpv",
        "colab_type": "text"
      },
      "source": [
        "In the forward propagation step, we are calculating the output and finally, in the backward propagation step, we are calculating the error. We will then update the weights and biases using this error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evq6gsFdBe_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "5db6d100-5f14-4bf9-8f3c-f20b2cc3cf3b"
      },
      "source": [
        "print('actual :\\n', y, '\\n')\n",
        "print('predicted :\\n', output)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "actual :\n",
            " tensor([[1.],\n",
            "        [1.],\n",
            "        [0.]]) \n",
            "\n",
            "predicted :\n",
            " tensor([[0.9980],\n",
            "        [0.9974],\n",
            "        [0.0048]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdMblif3Bmkx",
        "colab_type": "text"
      },
      "source": [
        "So, the target is 1, 1, 0 and the predicted values from the model are 0.98, 0.97 and 0.03. Not bad at all!"
      ]
    }
  ]
}